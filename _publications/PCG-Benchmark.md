---
title: "The Procedural Content Generation Benchmark: An Open-source Testbed for Generative Challenges in Games"
collection: publications
permalink: /publication/PCG-Benchmark
excerpt: ''
date: 2025-03-27
venue: 'International Conference on the Foundations of Digital Games'
paperurl: ''
citation: 'Khalifa, A., Gallotta, R., Barthet, M., Liapis, A., Togelius, J., & Yannakakis, G. N. (2025). The Procedural Content Generation Benchmark: An Open-source Testbed for Generative Challenges in Games. In Proceedings of the 20th International Conference on the Foundations of Digital Games.'
---

This paper introduces the Procedural Content Generation Benchmark for evaluating generative algorithms on different game content creation tasks. The benchmark comes with 12 game-related problems with multiple variants on each problem. Problems vary from creating levels of different kinds to creating rule sets for simple arcade games. Each problem has its own content representation, control parameters, and evaluation metrics for quality, diversity, and controllability. This benchmark is intended as a first step towards a standardized way of comparing generative algorithms. We use the benchmark to score three baseline algorithms: a random generator, an evolution strategy, and a genetic algorithm. Results show that some problems are easier to solve than others, as well as the impact the chosen objective has on quality, diversity, and controllability of the generated artifacts.

[Download paper here](http://matt-barthet.github.io/files/PCG-Benchmark.pdf)